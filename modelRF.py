# -*- coding: utf-8 -*-
"""PDS - 1 Algoritma

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IoYCZQIUtBNG0DamAdxHcjrZFWMv0JPc

### Tugas Proyek Data Science

 Nama: Nadea Putri Nur Fauzi

 NIM: 20110031

 Kelas: S1-SD-01A

Hyperparameter Tuning dan Feature Engineering Untuk Meningkatkan Akurasi Model Random Forest Pada Klasifikasi Risiko Kredit

## Data Acquisition
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""Sumber Dataset: https://www.kaggle.com/datasets/laotse/credit-risk-dataset"""

data = pd.read_csv('/content/drive/My Drive/dataset/CreditRisk.csv')
data.head()

data = data.rename(columns={'person_age': 'Umur','person_income':'Pendapatan','person_home_ownership':'KepemilikanRumah',
                            'person_emp_length':'LamaKerja','loan_intent':'TujuanPeminjaman','loan_grade':'TingkatanPinjaman',
                            'loan_amnt':'JumlahPinjaman','loan_int_rate':'SukuBunga','loan_status':'StatusPinjaman','loan_percent_income':'%Pendapatan',
                            'cb_person_default_on_file':'HistoriPeminjaman','cb_person_cred_hist_length':'JumlahHistoriPeminjaman'})

data.head()

"""###Variable Data

Diskrit

a.	Umur: Dalam Tahun

d.	Lama Kerja: Dalam Tahun

g.	Jumlah Pinjaman: Dolar

l.	Jumlah Histori Pinjaman
_____________________________

Kontinu

b.	Pendapatan: Dalam Dolar per Tahun

h.	Suku Bunga:

j.	Persentase Pinjaman:

_____________________________

kategorikal

c.	Kepemilikan Rumah:

e.	Tujuan Peminjaman:

f.	Grade Pinjaman:

i.	Status Pinjaman: KELAS

k.	Histori Pinjaman:

## Data Exploration
"""

data.shape

data.info()

data.describe()

sns.heatmap(data.corr(), annot=True)

data.isnull().sum()

print('Total Duplicated Values in dataframe are {0}'.format(data[data.duplicated()].shape[0]))

"""Cek Data Kategorikal"""

data.head()

categorical = data[['KepemilikanRumah','TujuanPeminjaman','TingkatanPinjaman','StatusPinjaman','HistoriPeminjaman']]

for column in categorical:
  value_counts = categorical[column].value_counts()
  print(f'Value Counts for column {column}:')
  print(value_counts)
  print('\n')

"""Data Numerik"""

data.head()

numeric = data[['Umur','Pendapatan','LamaKerja','JumlahPinjaman','SukuBunga','%Pendapatan','JumlahHistoriPeminjaman']]

numeric.describe()

sns.boxplot(data=numeric)
plt.xlabel('Kolom')
plt.ylabel('Nilai')
plt.title('Box Plot Data Numeric')
plt.show()

def count_outliers(data):
    columns = numeric
    outlier_counts = {}

    for column in columns:
        Q1 = data[column].quantile(0.25)
        Q3 = data[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]
        outlier_counts[column] = len(outliers)

    return outlier_counts

outlier_counts = count_outliers(data)
print(f'Jumlah Data Outliers adalah:', outlier_counts)

numeric.hist(bins=10, figsize=(10, 6))
plt.xlabel('Nilai')
plt.ylabel('Frekuensi')
plt.title('Histogram Data')
plt.show()

"""Data Kelas Target"""

data['StatusPinjaman'].value_counts()

viz=data.groupby('StatusPinjaman').size()
viz.plot(kind='bar', figsize=(4,3))

"""Dataset tidak balanced (Imbalanced dataset)

Hasil Eksplorasi Data:

1. Data null sejumlah 3116 pada kolom suku bunga dan 895 pada kolom lama kerja

Total Data Null = 4.011

2. Data outliers pada kolom 'Umur': 1494, 'Pendapatan': 1484, 'LamaKerja': 853, 'JumlahPinjaman': 1689, 'SukuBunga': 6, '%Pendapatan': 651 'JumlahHistoriPeminjaman': 1142.

Total Data Outliers = 7319

3. Data imbalanced | 25473 kelas 0 dan 7108 kelas 1.

### Data Cleaning

Data Duplicated
"""

data.drop_duplicates(inplace=True)

data.shape

"""Data Null/Kosong/NaN"""

mean_SB = data['SukuBunga'].mean()
data['SukuBunga'].fillna(mean_SB, inplace=True)

data.isnull().sum()

median_LK = data['LamaKerja'].median()
data['LamaKerja'].fillna(median_LK, inplace=True)

data.isnull().sum()

"""Data Kategorikal"""

categorical.head()

from sklearn.preprocessing import LabelEncoder

LE = [LabelEncoder(), LabelEncoder(), LabelEncoder(), LabelEncoder(), LabelEncoder()]

data['KepemilikanRumah'] = LE[0].fit_transform(data['KepemilikanRumah'])
data['TujuanPeminjaman'] = LE[1].fit_transform(data['TujuanPeminjaman'])
data['TingkatanPinjaman'] = LE[2].fit_transform(data['TingkatanPinjaman'])
data['StatusPinjaman'] = LE[3].fit_transform(data['StatusPinjaman'])
data['HistoriPeminjaman'] = LE[4].fit_transform(data['HistoriPeminjaman'])
data.head()

sns.boxplot(data=data['Umur'])

sns.boxplot(data=data['Pendapatan'])

filtered_data = data.loc[data['Pendapatan'] == 6000000]
filtered_data

"""akan didrop"""

sns.boxplot(data=data['LamaKerja'])

filtered_data1 = data.loc[data['LamaKerja'] >= 100]
filtered_data1

"""akan didrop"""

sns.boxplot(data=data['JumlahPinjaman'])

"""tidak didrop"""

sns.boxplot(data=data['SukuBunga'])

data = data.drop(data[(data['Umur'] >= 100) | (data['Pendapatan'] >= 6000000) | (data['LamaKerja'] >= 100)].index)

data.shape

data.head()

"""## Feature Engineering

Drop Feature
"""

data = data.drop(['HistoriPeminjaman', '%Pendapatan'], axis=1)

data.head()

data.shape

"""### Normalisasi"""

from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler

scaler = RobustScaler()
norm_cols = ['Pendapatan', 'JumlahPinjaman', 'SukuBunga','Umur']
data[norm_cols] = scaler.fit_transform(data[norm_cols])

data.head()

"""## Pre Modelling"""

x = data.drop(columns='StatusPinjaman')
y = data['StatusPinjaman']

x.shape, y.shape

from sklearn.model_selection import train_test_split, GridSearchCV

x_train, x_test, y_train, y_test = train_test_split(x,y ,train_size=0.75)

x_train.shape,x_test.shape

"""## Modelling

### Random Forest Algorithm
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

"""Dilakukan tuning parameter dengan melihat 4 parameter berikut:"""

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 5, 10],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]}

rf_model = RandomForestClassifier()

grid_search = GridSearchCV(rf_model, param_grid, cv=5)
grid_search.fit(x_train, y_train)

print("Best parameters found: ", grid_search.best_params_)
print("Best accuracy found: ", grid_search.best_score_)

"""Best parameter yang didapat yaitu:  'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200"""

best_model = grid_search.best_estimator_
test_accuracy = best_model.score(x_test, y_test)
print("Test accuracy: ", test_accuracy)

"""Hasil akurasi mencapai 92.3% yang artinya model yang dibuat sudah sangat baik."""

# model = RandomForestClassifier(n_estimators=100, random_state=42)
best_model.fit(x_train, y_train)
y_pred = best_model.predict(x_test)

accuracy = accuracy_score(y_test, y_pred)
print(accuracy)

from sklearn import tree

best_model = best_model.estimators_[0]

plt.figure(figsize=(10, 8))
tree.plot_tree(best_model,
               feature_names=x.columns,
               class_names=['0','1'],
               filled=True,
               precision=3)
plt.show()

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_pred,y_test)

plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt ='d', cmap='Reds')
plt.title('Confusion Matrix - Testing Data')
plt.xlabel('Prediksi')
plt.ylabel('Aktual')
plt.show()

from sklearn.metrics import classification_report
cr = classification_report(y_pred,y_test)
print(cr)

"""Untuk melihat model Random Forest ini, maka yang diperhatikan adalah nilai f1-scorenya."""

import pickle

with open('modelRF.pkl','wb') as f:
    pickle.dump(best_model,f)

with open('modelRF.pkl','wb') as f:
    pickle.dump(best_model,f)

filename = 'crc_trained.sav'
pickle.dump(best_model,open(filename,'wb'))

"""Predict"""

input_data = (25, 145000000, 2, 1,2,3,500000,11.14,2)

id_np_array = np.asarray(input_data)
id_reshaped = id_np_array.reshape(1,-1)

prediction = best_model.predict(id_reshaped)
print(prediction)

if(prediction[0]==0):
    print("Credit Status: Tidak Bermasalah")
else:
    print("Credit Status: Bermasalah")

